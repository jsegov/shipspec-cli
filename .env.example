# OpenAI API Key (for cloud LLM/embeddings)
OPENAI_API_KEY=sk-...

# Anthropic API Key (alternative)
# ANTHROPIC_API_KEY=sk-ant-...

# Mistral API Key (alternative)
# MISTRAL_API_KEY=...

# Google API Key (alternative)
# GOOGLE_API_KEY=...

# Tavily API Key (for web search/researcher)
TAVILY_API_KEY=tvly-...

# For local Ollama (optional)
# OLLAMA_BASE_URL=http://localhost:11434

# ============================================
# Advanced Configuration (Optional)
# ============================================

# Control dotenv loading behavior
# SHIPSPEC_LOAD_DOTENV=1                    # Set to 1 to force .env loading in production
# SHIPSPEC_DOTENV_PATH=/absolute/path/.env  # Absolute path to .env file (required in production if LOAD_DOTENV=1)
# SHIPSPEC_DOTENV_OVERRIDE=1                # Set to 1 to allow .env to override existing env vars
# SHIPSPEC_DOTENV_OVERRIDE_ACK=I_UNDERSTAND # Required acknowledgement if DOTENV_OVERRIDE=1 in production

# Strict configuration mode (enabled by default in production)
# SHIPSPEC_STRICT_CONFIG=1                  # Set to 1 to fail on malformed config files

# Debug and development flags
# SHIPSPEC_DEBUG_DIAGNOSTICS=1              # Enable verbose diagnostic logging
# ALLOW_LOCALHOST_LLM=1                     # Allow localhost URLs for LLM baseUrl (security: use only in dev)

# Node environment (automatically set by most deployment platforms)
# NODE_ENV=production                       # Set to 'production' for production deployments
